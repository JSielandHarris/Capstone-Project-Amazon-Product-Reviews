---
title: "Amazon Product Reviews Scraper"
author: "Jimmy Nguyen"
date: "07/07/2022"
output:
  pdf_document:
    latex_engine: xelatex
    toc: yes
    toc_depth: 5
  html_document:
    toc: yes
    toc_depth: '5'
    df_print: paged
---

\newpage


# Packages

```{r, warning=FALSE}
library(pacman)
library(pander)
pacman::p_load(RCurl, XML, dplyr, rvest, purrr)
```


# R-Function to Scrape Amazon Product Review

```{r}
amz_reviews_scraper <- function(page_num) {
  
  # verified purchase reviews only
  #url <- "https://www.amazon.com/Google-GA00439-US-Chromecast-3rd-Generation/product-reviews/B015UKRNGS/ref=cm_cr_arp_d_viewopt_srt?ie=UTF8&reviewerType=avp_only_reviews&pageNumber="
  
  # put product reviews url here (all reviews)
  url <- "https://www.amazon.com/Google-GA00439-US-Chromecast-3rd-Generation/product-reviews/B015UKRNGS/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber="
  url_reviews <- paste0(url, page_num)
  
  # read url and each page as html
  doc <- read_html(url_reviews)

  # parse the content
  map_dfr(doc %>% html_elements("[id^='customer_review']"), ~ data.frame(
    # extract tile
    review_title = .x %>% html_element(".review-title") %>% html_text2(),
    
    # extract review
    review_text = .x %>% html_element(".review-text-content") %>% html_text2(),
    
    # extract ratings
    review_star = .x %>% html_element(".review-rating") %>% html_text2(),
    
    # extract date of review
    date = .x %>% html_element(".review-date") %>% html_text2() %>% gsub(".*vom ", "", .),
    
    # extract author of review
    author = .x %>% html_element(".a-profile-name") %>% html_text2(),
    
    # extract page number of review page
    page = page_num
  )) %>%
    
    # return as table
    as_tibble %>%
    return()
}

```


# Combine Reviews into Dataframe and Export as CSV File

```{r, warning=FALSE}
# start timer
start.time <- Sys.time()

# put number of page here (each page extract 10 reviews)
page_num <- 20

# create data frame and append each review to the same data frame
df_total <- data.frame()

# loop over number of pages until desired number
for (x in 1:page_num) {
  # run scraper in each 
  each_page <- amz_reviews_scraper(page_num = x )
  
  # turn tibble into data frame
  df <- data.frame(each_page)
  
  # combine with original data frame
  df_total <- rbind(df_total, df)
}

# export to csv - make sure to specify the file name 
write.csv(df_total, "google_chromecast.csv", row.names = FALSE)


# end timer
end.time <- Sys.time()
time.taken <- round(end.time - start.time,2)
print(paste0("Total time alloted: ", time.taken))

```


\newpage

```{r, fig.align='center'}
# view data frame
head(df_total, 15) %>% select(review_text, review_star) %>%
  pander(style = "grid", caption = "Example of Amazon Web-Scraped Product Reviews")
```



